README  last modified: 21 April 2010 RAA
-------

=============================================================================
datarel  ISR/harness example
=============================================================================

In this example we run the ISR pipeline, launching it at the
level of pex_harness via the  launchPipeline.py script.

To run here at the pex_harness level, we perform by hand a couple of tasks
that ctrl_orca provides during "production" runs.

We link the input directory:

% ln -s /lsst/DC3/data/afwdata/trunk/ImSim input

and make the output directory :

% mkdir output update scratch work

The pipeline can be then started via :

%  launchPipeline.py  master.paf Run2 ISR -v | & tee ISR.log

The pipeline will block and wait for an incoming data event.
Provide this event with the trigger script: sendevent.py
When pipeline output displays: "Told JobOffice, I'm ready!",
capture the Origiator number for use in '-o' option to the sendevent command.

For, example, the following command corresponds to the ImSim dataset linked
above. BEWARE: as time passes, the ImSim dataset will morph.

sendevent.py -r Run2 -n ISR -b lsst8 assign IsrJob -O \
"postISR visit=85751839 snap=0 raft=R:2,3 sensor=S:1,1 channel=C:0,0" \
"raw visit=85751839 snap=0 raft=R:2,3 sensor=S:1,1 channel=C:0,0" \
-o    <fill in pipeline originator # provided by now waiting>

NOTE: can not break the long line right before '-O' --must be after or
get multiple dataset complaint. Also, can not break within quoted string or
will get embedded newline (which then is also interpreted as multiple output
datasets).

Note: contrary to doco, '-o' at end of command is OK; easier for cut-n-paste.


=================================================================
Example
=================================================================

Setup Environment
------------------

Most activity is done in local copy of: datarel/pipeline/ISR/harness.

Setup where your actual files are found or to be archived:
    I setup master.paf to have:
        runDirPattern: "../../../"
   Then in datarel, I've created the misc output directories;
         mkdir -p output work update scratch
   You should sym link to the local ImSim data directory
         ln -s /lsst/DC3/data/afwdata/trunk/ImSim input

   However, copying over the ImSim directory is OK, too (it's currently small)
         cp  -pr /lsst/DC3/data/afwdata/trunk/ImSim input


Running the pipeline
--------------------

The commands below are setup to enable copy-paste use in two previously
'setup' (eg, 'cd datarel; setup -r .') configured windows.


Window One:
-----------
cd datarel/pipeline/ISR/harness
rm Pipeline.log Slice0.log ISR.log
launchPipeline.py master.paf Run2 ISR -v | & tee ISR.log


Window Two:
-----------
When pipeline output in Window One says "Told JobOffice, I'm ready!",
send the  event providing the details of the specific input data to use.

sendevent.py -r Run2 -n ISR -b lsst8 assign IsrJob -O \
"postISR visit=85751839 snap=0 raft=R:2,3 sensor=S:1,1 channel=C:0,0" \
"raw visit=85751839 snap=0 raft=R:2,3 sensor=S:1,1 channel=C:0,0" \
-o    <fill in pipeline originator # provided by now waiting>


